# -*- coding: utf-8 -*-
"""ROC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18aF_eE5NnB0FS8-STJGPSc-_1lx3s-fH
"""

import pandas as pd
import numpy as np
import sklearn
import plotly
from sklearn.model_selection import train_test_split
import statsmodels.api as sm 
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_score
from numpy import mean
from numpy import std
from sklearn.model_selection import RepeatedKFold
from sklearn.model_selection import cross_val_score
from numpy import mean
from numpy import std
from sklearn.model_selection import RepeatedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn import metrics
import matplotlib.pyplot as plt

df = pd.read_csv("FinalTestData_1.csv")

dfTraining = df.iloc[:2770,:]
df2018 = df.iloc[2770:,:]

dfTraining.tail()

y = dfTraining['Winner']
cols = ['WPT','HWPT','AWPT','APPG']
X = dfTraining[cols]



X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state =5)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

svc = SVC(kernel='linear', probability=True)
svc.fit(X_train, y_train)
y_pred = svc.predict(X_test)
print('Accuracy of SVC {:.2f}'.format(svc.score(X_test , y_test)))



cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
scores3 = cross_val_score(svc, X_test, y_test, cv=cv, n_jobs=-1)
print('Score: %f (%f)' % (mean(scores3), std(scores3)))

from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
from matplotlib import pyplot


svcy_pred_proba = svc.predict_proba(X_test)[::,1]
svcfpr, svctpr, _ = metrics.roc_curve(y_test,  svcy_pred_proba)
svcauc = metrics.roc_auc_score(y_test, svcy_pred_proba)


ns_probs = [0 for _ in range(len(y_test))]
ns_auc = roc_auc_score(y_test, ns_probs)
ns_svcfpr, ns_svctpr, _ = roc_curve(y_test, ns_probs)
pyplot.plot(ns_svcfpr, ns_svctpr, linestyle='--', label='No Skill='+str(ns_auc))


plt.plot(svcfpr,svctpr,label="AUC="+str(svcauc))
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()

y = dfTraining['Winner']
cols = ['WPT','HWPT','AWPT','APPG']
X = dfTraining[cols]


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state =5)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

rf = RandomForestClassifier()
rf.fit(X_train, y_train)
y_pred = rf.predict(X_test)
print('Accuracy of RF  {:.2f}'.format(rf.score(X_test , y_test)))



cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
scores2 = cross_val_score(rf, X_test, y_test, cv=cv, n_jobs=-1)
print('Score: %f (%f)' % (mean(scores2), std(scores2)))

rfy_pred_proba = rf.predict_proba(X_test)[::,1]
rffpr, rftpr, _ = metrics.roc_curve(y_test,  rfy_pred_proba)
rfauc = metrics.roc_auc_score(y_test, rfy_pred_proba)


ns_probs = [0 for _ in range(len(y_test))]
ns_auc = roc_auc_score(y_test, ns_probs)
ns_rffpr, ns_rftpr, _ = roc_curve(y_test, ns_probs)
pyplot.plot(ns_rffpr, ns_rftpr, linestyle='--', label='No Skill='+str(ns_auc))


plt.plot(rffpr,rftpr,label="AUC="+str(rfauc))
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()

y = dfTraining['Winner']
cols = ['WPT','HWPT','AWPT','APPG']
X = dfTraining[cols]



X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state =5)
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

from sklearn.model_selection import cross_val_score
from numpy import mean
from numpy import std
from sklearn.model_selection import RepeatedKFold


logreg = LogisticRegression()
logreg.fit(X_train , y_train)
y_pred = logreg.predict(X_test)

cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
scores1 = cross_val_score(logreg, X_test, y_test, cv=cv, n_jobs=-1)
print('Score: %f (%f)' % (mean(scores1), std(scores1)))


print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test , y_test)))

lry_pred_proba = logreg.predict_proba(X_test)[::,1]
lrfpr, lrtpr, _ = metrics.roc_curve(y_test,  lry_pred_proba)
lrauc = metrics.roc_auc_score(y_test, lry_pred_proba)


ns_probs = [0 for _ in range(len(y_test))]
ns_auc = roc_auc_score(y_test, ns_probs)
ns_lrfpr, ns_lrtpr, _ = roc_curve(y_test, ns_probs)
pyplot.plot(ns_lrfpr, ns_lrtpr, linestyle='--', label='No Skill='+str(ns_auc))


plt.plot(lrfpr,lrtpr,label="AUC="+str(lrauc),color="blue")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()

ns_probs = [0 for _ in range(len(y_test))]
ns_auc = roc_auc_score(y_test, ns_probs)
ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)
pyplot.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill='+str(ns_auc))


plt.plot(svcfpr,svctpr,label="AUC="+str(svcauc),color="blue")
plt.plot(rffpr,rftpr,label="AUC="+str(rfauc),color="red")
plt.plot(lrfpr,lrtpr,label="AUC="+str(lrauc),color="green")
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.legend(loc=4)
plt.show()